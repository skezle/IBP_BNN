{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/samuelk/anaconda2/envs/tf-gpu-cuda8/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/nfs/home/samuelk/anaconda2/envs/tf-gpu-cuda8/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/nfs/home/samuelk/anaconda2/envs/tf-gpu-cuda8/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/nfs/home/samuelk/anaconda2/envs/tf-gpu-cuda8/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/nfs/home/samuelk/anaconda2/envs/tf-gpu-cuda8/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/nfs/home/samuelk/anaconda2/envs/tf-gpu-cuda8/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/nfs/home/samuelk/anaconda2/envs/tf-gpu-cuda8/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/nfs/home/samuelk/anaconda2/envs/tf-gpu-cuda8/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/nfs/home/samuelk/anaconda2/envs/tf-gpu-cuda8/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/nfs/home/samuelk/anaconda2/envs/tf-gpu-cuda8/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/nfs/home/samuelk/anaconda2/envs/tf-gpu-cuda8/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/nfs/home/samuelk/anaconda2/envs/tf-gpu-cuda8/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gzip\n",
    "import pickle\n",
    "import sys\n",
    "import copy\n",
    "import os.path\n",
    "import pdb\n",
    "import re\n",
    "from run_split import SplitMnistGenerator, SplitMnistRandomGenerator\n",
    "from run_permuted import PermutedMnistGenerator\n",
    "from alg.cla_models_multihead import MFVI_NN, Vanilla_NN\n",
    "from alg.HIBP_BNN_multihead import HIBP_BNN\n",
    "from alg.IBP_BNN_multihead import IBP_BNN\n",
    "from hibp_weight_pruning import prune_weights, MnistGenerator\n",
    "from alg.utils import get_scores, get_scores_entropy, concatenate_results, get_uncertainties\n",
    "from alg.vcl import run_vcl\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /nfs/home/samuelk/IBP_BNN/src/alg/cla_models_multihead.py:53: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /nfs/home/samuelk/IBP_BNN/src/alg/cla_models_multihead.py:175: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /nfs/home/samuelk/IBP_BNN/src/alg/cla_models_multihead.py:58: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /nfs/home/samuelk/IBP_BNN/src/alg/cla_models_multihead.py:62: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /nfs/home/samuelk/IBP_BNN/src/alg/cla_models_multihead.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch: 0001 cost= 0.053171204\n",
      "Epoch: 0006 cost= 0.000736305\n",
      "WARNING:tensorflow:From /nfs/home/samuelk/IBP_BNN/src/alg/IBP_BNN_multihead.py:131: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /nfs/home/samuelk/IBP_BNN/src/alg/IBP_BNN_multihead.py:144: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /nfs/home/samuelk/IBP_BNN/src/alg/IBP_BNN_multihead.py:74: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /nfs/home/samuelk/anaconda2/envs/tf-gpu-cuda8/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /nfs/home/samuelk/IBP_BNN/src/alg/IBP_BNN_multihead.py:81: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "Z: (1, ?, 100)\n",
      "WARNING:tensorflow:From /nfs/home/samuelk/IBP_BNN/src/alg/IBP_BNN_multihead.py:247: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /nfs/home/samuelk/anaconda2/envs/tf-gpu-cuda8/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../ddm/logs/graph_split_normal_run2_split_normal_l1_mh_task1/model.ckpt\n",
      "Z: (1, ?, 100)\n",
      "INFO:tensorflow:Restoring parameters from ../ddm/logs/graph_split_normal_run2_split_normal_l1_mh_task2/model.ckpt\n",
      "Z: (1, ?, 100)\n",
      "INFO:tensorflow:Restoring parameters from ../ddm/logs/graph_split_normal_run2_split_normal_l1_mh_task3/model.ckpt\n",
      "Z: (1, ?, 100)\n",
      "INFO:tensorflow:Restoring parameters from ../ddm/logs/graph_split_normal_run2_split_normal_l1_mh_task4/model.ckpt\n",
      "Z: (1, ?, 100)\n",
      "INFO:tensorflow:Restoring parameters from ../ddm/logs/graph_split_normal_run2_split_normal_l1_mh_task5/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "hidden_size = [100]\n",
    "batch_size = 128\n",
    "no_epochs = 100\n",
    "run = 2\n",
    "val = False\n",
    "cl2=True\n",
    "cl3=False\n",
    "#data_gen = SplitMnistRandomGenerator(val)\n",
    "data_gen = SplitMnistGenerator(val, cl3)\n",
    "all_acc, all_acc_ent = np.array([]), np.array([]) \n",
    "all_uncerts_split, accs = {}, {}\n",
    "all_x_testsets, all_y_testsets = [], []\n",
    "x_testsets, y_testsets = [], []\n",
    "\n",
    "for task_id in range(data_gen.max_iter):\n",
    "    np.random.seed(1)\n",
    "    if val:\n",
    "        _, _, x_test, y_test, _, _ = data_gen.next_task()\n",
    "    else:\n",
    "        _, _, x_test, y_test = data_gen.next_task()\n",
    "    all_x_testsets.append(x_test)\n",
    "    all_y_testsets.append(y_test)\n",
    "\n",
    "data_gen.reset_cur_iter()\n",
    "coreset_size = 0\n",
    "single_head=False\n",
    "in_dim, out_dim = data_gen.get_dims()\n",
    "for task_id in range(data_gen.max_iter):\n",
    "\n",
    "    tf.reset_default_graph()  \n",
    "    tf.set_random_seed(1)\n",
    "    np.random.seed(1)\n",
    "    if val:\n",
    "        x_train, y_train, x_test, y_test, _, _ = data_gen.next_task()\n",
    "    else:\n",
    "        x_train, y_train, x_test, y_test = data_gen.next_task()\n",
    "    x_testsets.append(x_test)\n",
    "    y_testsets.append(y_test)\n",
    "\n",
    "    # Set the readout head to train\n",
    "    head = 0 if single_head else task_id\n",
    "    bsize = x_train.shape[0] if (batch_size is None) else batch_size\n",
    "\n",
    "    # Train network with maximum likelihood to initialize first model\n",
    "    if task_id == 0:\n",
    "        ml_model = Vanilla_NN(in_dim, hidden_size, out_dim, x_train.shape[0])\n",
    "        ml_model.train(x_train, y_train, task_id, 10, bsize)\n",
    "        mf_weights = ml_model.get_weights()\n",
    "        mf_variances = None\n",
    "        mf_betas = None\n",
    "        ml_model.close_session()\n",
    "\n",
    "    # Train on non-coreset data\n",
    "    model = IBP_BNN(input_size=in_dim, \n",
    "                     hidden_size=hidden_size, \n",
    "                     output_size=out_dim, \n",
    "                     training_size=x_train.shape[0], \n",
    "                     no_train_samples=10,\n",
    "                     no_pred_samples=100,\n",
    "                     num_ibp_samples=10, prev_means=mf_weights, \n",
    "                     prev_log_variances=mf_variances, \n",
    "                     prev_betas=mf_betas,\n",
    "                     learning_rate=0.001, learning_rate_decay=0.87,\n",
    "                     prior_mean=0.0, prior_var=0.7,\n",
    "                     alpha0=5.0, beta0=1.0,\n",
    "                     lambda_1=1.0, lambda_2=1.0,\n",
    "                     tensorboard_dir='../ddm/logs',\n",
    "                     #name='ibp_rs_opt_split_random_noise_rs_l1_mh_run{0}_task{1}'.format(run, task_id+1),\n",
    "                     name='split_normal_run{0}_split_normal_l1_mh_task{1}'.format(run, task_id+1),\n",
    "                     #name='ibp_perm_run{0}_perm_l1_mh_new_task{1}'.format(run, task_id+1),\n",
    "                     use_local_reparam=False, implicit_beta=True)\n",
    "    # graph_split_normal_run3_split_normal_l1_mh_task4\n",
    "    # graph_ibp_rs_opt_split_random_noise_rs_l1_mh_run1_task1\n",
    "    # graph_ibp_perm_run1_perm_l1_mh_new_task1\n",
    "    model.create_model()\n",
    "    #model.restore(os.path.join(\"logs_rs\", 'graph_ibp_rs_opt_{0}'.format('split_random_noise_rs_l1_mh_run{0}_task{1}'.format(run, task_id+1))))\n",
    "    model.restore(model.log_folder)\n",
    "    \n",
    "    mf_weights, mf_variances, mf_betas = model.get_weights()\n",
    "    \n",
    "    acc = get_scores(model, x_testsets, y_testsets, bsize, single_head)\n",
    "    acc_ent = get_scores_entropy(model, x_testsets, y_testsets, bsize, data_gen.max_iter)\n",
    "    all_acc = concatenate_results(acc, all_acc)\n",
    "    all_acc_ent = concatenate_results(acc_ent, all_acc_ent)\n",
    "    \n",
    "    model.close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9984421 ,        nan,        nan,        nan,        nan],\n",
       "       [0.98419577, 0.97999464,        nan,        nan,        nan],\n",
       "       [0.8547196 , 0.95980069, 0.99275712,        nan,        nan],\n",
       "       [0.73139583, 0.94299157, 0.98591057, 0.99436583,        nan],\n",
       "       [0.75060867, 0.93856502, 0.97401715, 0.97940608, 0.98178935]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.936597330611126"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(all_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99827706,        nan,        nan,        nan,        nan],\n",
       "       [0.9835478 , 0.97983678,        nan,        nan,        nan],\n",
       "       [0.84818763, 0.96132315, 0.99132965,        nan,        nan],\n",
       "       [0.73607537, 0.94078869, 0.98609616, 0.99474668,        nan],\n",
       "       [0.58356247, 0.55603075, 0.97380868, 0.9789752 , 0.98039559]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_acc_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8995321111379837"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(all_acc_ent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permuted MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /nfs/home/samuelk/IBP_BNN/src/alg/cla_models_multihead.py:53: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /nfs/home/samuelk/IBP_BNN/src/alg/cla_models_multihead.py:175: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /nfs/home/samuelk/IBP_BNN/src/alg/cla_models_multihead.py:58: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /nfs/home/samuelk/IBP_BNN/src/alg/cla_models_multihead.py:62: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /nfs/home/samuelk/IBP_BNN/src/alg/cla_models_multihead.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch: 0001 cost= 0.460927513\n",
      "Epoch: 0006 cost= 0.087805614\n",
      "WARNING:tensorflow:From /nfs/home/samuelk/IBP_BNN/src/alg/IBP_BNN_multihead.py:131: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /nfs/home/samuelk/IBP_BNN/src/alg/IBP_BNN_multihead.py:144: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /nfs/home/samuelk/IBP_BNN/src/alg/IBP_BNN_multihead.py:74: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /nfs/home/samuelk/anaconda2/envs/tf-gpu-cuda8/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /nfs/home/samuelk/IBP_BNN/src/alg/IBP_BNN_multihead.py:81: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "Z: (1, ?, 100)\n",
      "WARNING:tensorflow:From /nfs/home/samuelk/IBP_BNN/src/alg/IBP_BNN_multihead.py:247: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /nfs/home/samuelk/anaconda2/envs/tf-gpu-cuda8/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../ddm/logs_perm/graph_ibp_perm_run2_perm_l1_mh_new_task1/model.ckpt\n",
      "> /nfs/home/samuelk/IBP_BNN/src/alg/utils.py(88)get_scores_entropy()\n",
      "-> head = np.argmin(uncerts)\n",
      "(Pdb) c\n",
      "Z: (1, ?, 100)\n",
      "INFO:tensorflow:Restoring parameters from ../ddm/logs_perm/graph_ibp_perm_run2_perm_l1_mh_new_task2/model.ckpt\n",
      "> /nfs/home/samuelk/IBP_BNN/src/alg/utils.py(88)get_scores_entropy()\n",
      "-> head = np.argmin(uncerts)\n",
      "(Pdb) c\n",
      "> /nfs/home/samuelk/IBP_BNN/src/alg/utils.py(87)get_scores_entropy()\n",
      "-> pdb.set_trace()\n",
      "(Pdb) uncerts\n",
      "[0.828159, 0.2618167, 2.2624934, 2.263195, 2.263002]\n",
      "(Pdb) all_acc_ent\n",
      "*** NameError: name 'all_acc_ent' is not defined\n",
      "(Pdb) c\n",
      "Z: (1, ?, 100)\n",
      "INFO:tensorflow:Restoring parameters from ../ddm/logs_perm/graph_ibp_perm_run2_perm_l1_mh_new_task3/model.ckpt\n",
      "> /nfs/home/samuelk/IBP_BNN/src/alg/utils.py(88)get_scores_entropy()\n",
      "-> head = np.argmin(uncerts)\n",
      "(Pdb) uncerts\n",
      "[0.148795, 0.94619495, 1.1145574, 2.2630858, 2.2637508]\n",
      "(Pdb) c\n",
      "> /nfs/home/samuelk/IBP_BNN/src/alg/utils.py(87)get_scores_entropy()\n",
      "-> pdb.set_trace()\n",
      "(Pdb) uncerts\n",
      "[0.7800675, 0.24224547, 0.9768412, 2.2615278, 2.2620742]\n",
      "(Pdb) n\n",
      "> /nfs/home/samuelk/IBP_BNN/src/alg/utils.py(88)get_scores_entropy()\n",
      "-> head = np.argmin(uncerts)\n",
      "(Pdb) c\n",
      "> /nfs/home/samuelk/IBP_BNN/src/alg/utils.py(87)get_scores_entropy()\n",
      "-> pdb.set_trace()\n",
      "(Pdb) uncerts\n",
      "[0.8748192, 1.0581592, 0.24778017, 2.2629614, 2.2627327]\n",
      "(Pdb) n\n",
      "> /nfs/home/samuelk/IBP_BNN/src/alg/utils.py(88)get_scores_entropy()\n",
      "-> head = np.argmin(uncerts)\n",
      "(Pdb) c\n",
      "Z: (1, ?, 100)\n",
      "INFO:tensorflow:Restoring parameters from ../ddm/logs_perm/graph_ibp_perm_run2_perm_l1_mh_new_task4/model.ckpt\n",
      "> /nfs/home/samuelk/IBP_BNN/src/alg/utils.py(88)get_scores_entropy()\n",
      "-> head = np.argmin(uncerts)\n",
      "(Pdb) c\n",
      "> /nfs/home/samuelk/IBP_BNN/src/alg/utils.py(87)get_scores_entropy()\n",
      "-> pdb.set_trace()\n",
      "(Pdb) uncets\n",
      "*** NameError: name 'uncets' is not defined\n",
      "(Pdb) uncerts\n",
      "[0.7398492, 0.20604222, 0.92314804, 1.0288353, 2.2624402]\n",
      "(Pdb) c\n",
      "> /nfs/home/samuelk/IBP_BNN/src/alg/utils.py(88)get_scores_entropy()\n",
      "-> head = np.argmin(uncerts)\n",
      "(Pdb) c\n",
      "> /nfs/home/samuelk/IBP_BNN/src/alg/utils.py(87)get_scores_entropy()\n",
      "-> pdb.set_trace()\n",
      "(Pdb) uncerts\n",
      "[0.73351073, 1.1102682, 0.97618026, 0.24473381, 2.2613528]\n",
      "(Pdb) c\n",
      "Z: (1, ?, 100)\n",
      "INFO:tensorflow:Restoring parameters from ../ddm/logs_perm/graph_ibp_perm_run2_perm_l1_mh_new_task5/model.ckpt\n",
      "> /nfs/home/samuelk/IBP_BNN/src/alg/utils.py(88)get_scores_entropy()\n",
      "-> head = np.argmin(uncerts)\n",
      "(Pdb) uncerts\n",
      "[0.14779875, 0.91887444, 1.0537393, 1.0515386, 1.0122185]\n",
      "(Pdb) c\n",
      "> /nfs/home/samuelk/IBP_BNN/src/alg/utils.py(87)get_scores_entropy()\n",
      "-> pdb.set_trace()\n",
      "(Pdb) c\n",
      "> /nfs/home/samuelk/IBP_BNN/src/alg/utils.py(88)get_scores_entropy()\n",
      "-> head = np.argmin(uncerts)\n",
      "(Pdb) c\n",
      "> /nfs/home/samuelk/IBP_BNN/src/alg/utils.py(87)get_scores_entropy()\n",
      "-> pdb.set_trace()\n",
      "(Pdb) c\n",
      "> /nfs/home/samuelk/IBP_BNN/src/alg/utils.py(88)get_scores_entropy()\n",
      "-> head = np.argmin(uncerts)\n",
      "(Pdb) c\n"
     ]
    }
   ],
   "source": [
    "hidden_size = [100]\n",
    "batch_size = 128\n",
    "no_epochs = 100\n",
    "run = 2\n",
    "val = True\n",
    "data_gen = PermutedMnistGenerator(max_iter=5, val=val)\n",
    "all_acc, all_acc_ent = np.array([]), np.array([]) \n",
    "x_testsets, y_testsets = [], []\n",
    "\n",
    "# permutations are need to be correct\n",
    "for task_id in range(data_gen.max_iter):\n",
    "    np.random.seed(1)\n",
    "    if val:\n",
    "        _, _, x_test, y_test, _, _ = data_gen.next_task()\n",
    "    else:\n",
    "        _, _, x_test, y_test = data_gen.next_task()\n",
    "\n",
    "data_gen.reset_cur_iter()\n",
    "coreset_size = 0\n",
    "single_head=False\n",
    "in_dim, out_dim = data_gen.get_dims()\n",
    "for task_id in range(data_gen.max_iter):\n",
    "\n",
    "    tf.reset_default_graph()  \n",
    "    tf.set_random_seed(1)\n",
    "    np.random.seed(1)\n",
    "    if val:\n",
    "        x_train, y_train, x_test, y_test, _, _ = data_gen.next_task()\n",
    "    else:\n",
    "        x_train, y_train, x_test, y_test = data_gen.next_task()\n",
    "    x_testsets.append(x_test)\n",
    "    y_testsets.append(y_test)\n",
    "\n",
    "    # Set the readout head to train\n",
    "    head = 0 if single_head else task_id\n",
    "    bsize = x_train.shape[0] if (batch_size is None) else batch_size\n",
    "\n",
    "    # Train network with maximum likelihood to initialize first model\n",
    "    if task_id == 0:\n",
    "        ml_model = Vanilla_NN(in_dim, hidden_size, out_dim, x_train.shape[0])\n",
    "        ml_model.train(x_train, y_train, task_id, 10, bsize)\n",
    "        mf_weights = ml_model.get_weights()\n",
    "        mf_variances = None\n",
    "        mf_betas = None\n",
    "        ml_model.close_session()\n",
    "\n",
    "    # Train on non-coreset data\n",
    "    model = IBP_BNN(input_size=in_dim, \n",
    "                     hidden_size=hidden_size, \n",
    "                     output_size=out_dim, \n",
    "                     training_size=x_train.shape[0], \n",
    "                     no_train_samples=10,\n",
    "                     no_pred_samples=100,\n",
    "                     num_ibp_samples=10, prev_means=mf_weights, \n",
    "                     prev_log_variances=mf_variances, \n",
    "                     prev_betas=mf_betas,\n",
    "                     learning_rate=0.001, learning_rate_decay=0.87,\n",
    "                     prior_mean=0.0, prior_var=0.7,\n",
    "                     alpha0=5.0, beta0=1.0,\n",
    "                     lambda_1=1.0, lambda_2=1.0,\n",
    "                     tensorboard_dir='../ddm/logs_perm',\n",
    "                     #name='ibp_rs_opt_split_random_noise_rs_l1_mh_run{0}_task{1}'.format(run, task_id+1),\n",
    "                     #name='split_normal_run{0}_split_normal_l1_mh_task{1}'.format(run, task_id+1),\n",
    "                     name='ibp_perm_run{0}_perm_l1_mh_new_task{1}'.format(run, task_id+1),\n",
    "                     use_local_reparam=False, implicit_beta=True)\n",
    "    # graph_split_normal_run3_split_normal_l1_mh_task4\n",
    "    # graph_ibp_rs_opt_split_random_noise_rs_l1_mh_run1_task1\n",
    "    # graph_ibp_perm_run1_perm_l1_mh_new_task1\n",
    "    model.create_model()\n",
    "    #model.restore(os.path.join(\"logs_rs\", 'graph_ibp_rs_opt_{0}'.format('split_random_noise_rs_l1_mh_run{0}_task{1}'.format(run, task_id+1))))\n",
    "    model.restore(model.log_folder)\n",
    "    \n",
    "    mf_weights, mf_variances, mf_betas = model.get_weights()\n",
    "    \n",
    "    acc = get_scores(model, x_testsets, y_testsets, bsize, single_head)\n",
    "    acc_ent = get_scores_entropy(model, x_testsets, y_testsets, bsize, data_gen.max_iter)\n",
    "    all_acc = concatenate_results(acc, all_acc)\n",
    "    all_acc_ent = concatenate_results(acc_ent, all_acc_ent)\n",
    "    \n",
    "    model.close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9535977 ,        nan,        nan,        nan,        nan],\n",
       "       [0.94893295, 0.93817939,        nan,        nan,        nan],\n",
       "       [0.9403392 , 0.92611155, 0.94079213,        nan,        nan],\n",
       "       [0.9393928 , 0.92944324, 0.93385779, 0.93991891,        nan],\n",
       "       [0.93400712, 0.92507812, 0.91658129, 0.93453026, 0.94003758]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95370748,        nan,        nan,        nan,        nan],\n",
       "       [0.94896855, 0.93819521,        nan,        nan,        nan],\n",
       "       [0.94024229, 0.9255805 , 0.93989122,        nan,        nan],\n",
       "       [0.93934336, 0.92972508, 0.93446301, 0.93967563,        nan],\n",
       "       [0.93397449, 0.92504055, 0.91725573, 0.93454905, 0.94088014]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_acc_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu-cuda8] *",
   "language": "python",
   "name": "conda-env-tf-gpu-cuda8-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
