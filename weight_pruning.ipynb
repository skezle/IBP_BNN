{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gzip\n",
    "import pickle\n",
    "import sys\n",
    "import copy\n",
    "import os.path\n",
    "import pdb\n",
    "import re\n",
    "from ddm.run_split import SplitMnistGenerator\n",
    "from ddm.alg.cla_models_multihead import MFVI_IBP_NN, MFVI_NN, Vanilla_NN\n",
    "from ddm.alg.utils import get_scores, concatenate_results\n",
    "from ddm.alg.vcl import run_vcl\n",
    "from copy import deepcopy\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFVI_IBP_NN_prune(MFVI_IBP_NN):\n",
    "    def __init__(self, input_size, hidden_size, output_size, training_size, num_ibp_samples=10,\n",
    "                 no_train_samples=10, no_pred_samples=100, prev_means=None, prev_log_variances=None,\n",
    "                 prev_betas=None, learning_rate=0.0001,\n",
    "                 prior_mean=0, prior_var=1, alpha0=5., beta0=1., lambda_1=1., lambda_2=1.,\n",
    "                 tensorboard_dir='logs', name='ibp_wp', min_temp=0.5, tb_logging=True,\n",
    "                output_tb_gradients=True):\n",
    "\n",
    "        super(MFVI_IBP_NN_prune, self).__init__(input_size, hidden_size, output_size, training_size,\n",
    "                 no_train_samples, no_pred_samples, num_ibp_samples, prev_means, prev_log_variances,\n",
    "                 prev_betas, learning_rate,\n",
    "                 prior_mean, prior_var, alpha0, beta0, lambda_1, lambda_2,\n",
    "                 tensorboard_dir, name, min_temp, tb_logging, output_tb_gradients=True)\n",
    "\n",
    "\n",
    "    def prune_weights(self, X_test, Y_test, task_id):\n",
    "        \"\"\" Performs weight pruning.\n",
    "        \n",
    "        Z is at a data level doesn't make sense to introduce this intot he mask over weights which get zeroed \n",
    "        out. Simlpy running the accuracy over the graph will entail that Z is incorporated into the \n",
    "        matrix math for the prediction calculations.\n",
    "        \n",
    "        Args:\n",
    "            X_test: numpy array\n",
    "            Y_test: numpy array\n",
    "            task_id: int\n",
    "        :return: cutoffs, accs via naive pruning, accs via snr pruning,\n",
    "        weight values, sigma values of network\n",
    "        \"\"\"\n",
    "\n",
    "        def reset_weights(pr_mus, pr_sigmas, _mus, _sigmas):\n",
    "            \"\"\" Reset weights of graph to original values\n",
    "            Args:\n",
    "                pr_mus: list of tf variables which have been pruned\n",
    "                pr_sigmas: list of tf variables which have been pruned\n",
    "                _mus: list of cached mus in numpy\n",
    "                _sigmas: list of cached sigmas in numpy\n",
    "            \"\"\"\n",
    "\n",
    "            for v, _v in zip(pr_mus, _mus):\n",
    "                self.sess.run(tf.assign(v, tf.cast(_v, v.dtype)))\n",
    "\n",
    "            for v, _v in zip(pr_sigmas, _sigmas):\n",
    "                self.sess.run(tf.assign(v, tf.cast(_v, v.dtype)))\n",
    "\n",
    "        def pruning(remove_pct, weightvalues, sigmavalues,\n",
    "                    weights, sigmas, uncert_pruning=True):\n",
    "            \"\"\" Performs weight pruning experiment\n",
    "            Args:\n",
    "                weightvalues: np array of weights\n",
    "                sigmavalues: np array of sigmas\n",
    "                weights: list of tf weight variable\n",
    "                new_weights: list of new tf weight variables which wil\n",
    "                sigmas: list of tf sigma variables\n",
    "                uncert_pruning: bool pruning by snr\n",
    "            \"\"\"\n",
    "            if uncert_pruning:\n",
    "                sorted_STN = np.sort(np.abs(weightvalues) / sigmavalues)\n",
    "                \n",
    "            else:\n",
    "                sorted_STN = np.sort(np.abs(weightvalues))\n",
    "            cutoff = sorted_STN[int(remove_pct * len(sorted_STN))]\n",
    "            \n",
    "            # Weights, biases and head weights\n",
    "            for v, s in zip(weights, sigmas):\n",
    "                if uncert_pruning:\n",
    "                    snr = tf.abs(v) / tf.exp(0.5*s)\n",
    "                    mask = tf.greater_equal(snr, cutoff)\n",
    "                else:\n",
    "                    mask = tf.greater_equal(tf.abs(v), cutoff)\n",
    "                self.sess.run(tf.assign(v, tf.multiply(v, tf.cast(mask, v.dtype))))\n",
    "                #self.sess.run(tf.assign(s, np.multiply(self.sess.run(s), mask)))  # also apply zero std to weight!!!\n",
    "                \n",
    "            accs = []\n",
    "            for _ in range(10):\n",
    "                accs.append(self.sess.run(self.acc, {self.x: X_test,\n",
    "                                                     self.y: Y_test,\n",
    "                                                     self.task_idx: task_id,\n",
    "                                                     self.temp: self.lambda_1,\n",
    "                                                     self.training: False}))\n",
    "            print(\"%.2f, %s\" % (np.sum(sorted_STN < cutoff) / len(sorted_STN), np.mean(accs)))\n",
    "            return np.mean(accs)\n",
    "\n",
    "        # get weights\n",
    "        weights = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=tf.get_variable_scope().name)\n",
    "        \n",
    "        # Get weights from network\n",
    "        # TODO get head weights and biases\n",
    "        mus_w = []\n",
    "        mus_b = []\n",
    "        sigmas_w = []\n",
    "        sigmas_b = []\n",
    "        mus_h = [] # weights and biases\n",
    "        sigmas_h = [] # weights and biases\n",
    "        for v in weights:\n",
    "            if re.match(\"^([w])(_mu_)([0-9]+)(:0)$\", v.name):\n",
    "                mus_w.append(v)\n",
    "            elif re.match(\"^([w])(_sigma_)([0-9]+)(:0)$\", v.name):\n",
    "                sigmas_w.append(v)\n",
    "            elif re.match(\"^([b])(_mu_)([0-9]+)(:0)$\", v.name):\n",
    "                mus_b.append(v)\n",
    "            elif re.match(\"^([b])(_sigma_)([0-9]+)(:0)$\", v.name):\n",
    "                sigmas_b.append(v)\n",
    "            elif re.match(\"^([wb])(_mu_h_)([0-9]+)(:0)$\", v.name):\n",
    "                mus_h.append(v)\n",
    "            elif re.match(\"^([wb])(_sigma_h_)([0-9]+)(:0)$\", v.name):\n",
    "                sigmas_h.append(v)\n",
    "            else:\n",
    "                print(\"Un-matched: {}\".format(v.name))\n",
    "                \n",
    "        acc = self.sess.run(self.acc, {self.x: X_test,\n",
    "                                    self.y: Y_test,\n",
    "                                    self.task_idx: task_id,\n",
    "                                    self.temp: self.lambda_1,\n",
    "                                    self.training: False}) # z mask for each layer in a list, each Z \\in dout\n",
    "        print(\"test acc: {}\".format(acc))\n",
    "        # cache network weights of resetting the network\n",
    "        _mus_w = [self.sess.run(w) for w in mus_w]\n",
    "        _sigmas_w = [self.sess.run(w) for w in sigmas_w]\n",
    "        _mus_b = [self.sess.run(w) for w in mus_b]\n",
    "        _sigmas_b = [self.sess.run(w) for w in sigmas_b]\n",
    "        _mus_h = [self.sess.run(w) for w in mus_h]\n",
    "        _sigmas_h = [self.sess.run(w) for w in sigmas_h]\n",
    "        \n",
    "        weightvalues = np.hstack(np.array([self.sess.run(w).flatten() for w in mus_w + mus_b + mus_h]))\n",
    "        sigmavalues = np.hstack(np.array([self.sess.run(tf.exp(0.5*s)).flatten() for s in sigmas_w + sigmas_b + sigmas_h]))\n",
    "    \n",
    "        xs = np.append(0.05 * np.array(range(20)), np.array([0.98, 0.99, 0.999]))\n",
    "        ya_ibp = []\n",
    "        for pct in xs:\n",
    "            ya_ibp.append(pruning(pct, weightvalues, sigmavalues, mus_w + mus_b + mus_h,\n",
    "                              sigmas_w + sigmas_b + sigmas_h, uncert_pruning=False))\n",
    "\n",
    "        # reset etc.\n",
    "        reset_weights(mus_w, sigmas_w, _mus_w, _sigmas_w)\n",
    "        reset_weights(mus_b, sigmas_b, _mus_b, _sigmas_b)\n",
    "        reset_weights(mus_h, sigmas_h, _mus_h, _sigmas_h)\n",
    "        yb_ibp = []\n",
    "        for pct in xs:\n",
    "            yb_ibp.append(pruning(pct, weightvalues, sigmavalues, mus_w + mus_b + mus_h,\n",
    "                                  sigmas_w + sigmas_b + sigmas_h, uncert_pruning=True))\n",
    "            \n",
    "        reset_weights(mus_w, sigmas_w, _mus_w, _sigmas_w)\n",
    "        reset_weights(mus_b, sigmas_b, _mus_b, _sigmas_b)\n",
    "        reset_weights(mus_h, sigmas_h, _mus_h, _sigmas_h)\n",
    "        \n",
    "        #return xs, ya, yb, ya_ibp, yb_ibp\n",
    "        return xs, ya_ibp, yb_ibp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass CLF Weight Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistGenerator():\n",
    "    def __init__(self, max_iter=10):\n",
    "        with gzip.open('ddm/data/mnist.pkl.gz', 'rb') as f:\n",
    "            train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "\n",
    "        self.X_train = np.vstack((train_set[0], valid_set[0]))\n",
    "        self.Y_train = np.hstack((train_set[1], valid_set[1]))\n",
    "        self.X_test = test_set[0]\n",
    "        self.Y_test = test_set[1]\n",
    "        self.max_iter = max_iter\n",
    "        self.cur_iter = 0\n",
    "\n",
    "    def get_dims(self):\n",
    "        # Get data input and output dimensions\n",
    "        return self.X_train.shape[1], 10\n",
    "\n",
    "    def task(self):\n",
    "        # Retrieve train data\n",
    "        x_train = deepcopy(self.X_train)\n",
    "        y_train = np.eye(10)[self.Y_train]\n",
    "\n",
    "        # Retrieve test data\n",
    "        x_test = deepcopy(self.X_test)\n",
    "        y_test = np.eye(10)[self.Y_test]\n",
    "        \n",
    "        return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.426189762\n",
      "Epoch: 0006 cost= 0.072720788\n",
      "Epoch: 0011 cost= 0.034669463\n",
      "Epoch: 0016 cost= 0.016965997\n",
      "Epoch: 0021 cost= 0.009314988\n",
      "Epoch: 0026 cost= 0.004378363\n",
      "Epoch: 0031 cost= 0.002213837\n",
      "Epoch: 0036 cost= 0.003966764\n",
      "Epoch: 0041 cost= 0.000496028\n",
      "Epoch: 0046 cost= 0.000379165\n",
      "Epoch: 0051 cost= 0.007840798\n",
      "Epoch: 0056 cost= 0.000209307\n",
      "Epoch: 0061 cost= 0.004998238\n",
      "Epoch: 0066 cost= 0.000127207\n",
      "Epoch: 0071 cost= 0.009636767\n",
      "Epoch: 0076 cost= 0.000103964\n",
      "Epoch: 0081 cost= 0.000062058\n",
      "Epoch: 0086 cost= 0.000225862\n",
      "Epoch: 0091 cost= 0.000057764\n",
      "Epoch: 0096 cost= 0.000036915\n",
      "Optimization Finished!\n",
      "(1, ?, 100)\n",
      "<unknown>\n",
      "(1, ?, 100)\n",
      "<unknown>\n",
      "(1, ?, 100)\n",
      "<unknown>\n",
      "_Z: (1, ?, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0823 10:12:40.886374 140264918792000 deprecation_wrapper.py:119] From /home/skessler/Projects/IBP_BNN/ddm/alg/cla_models_multihead.py:965: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train cost= 5.082051569\n",
      "Epoch: 0006 train cost= 4.157539167\n",
      "Epoch: 0011 train cost= 3.840953959\n",
      "Epoch: 0016 train cost= 3.657530600\n",
      "Epoch: 0021 train cost= 3.520703846\n",
      "Epoch: 0026 train cost= 3.411455073\n",
      "Epoch: 0031 train cost= 3.317287026\n",
      "Epoch: 0036 train cost= 3.229020371\n",
      "Epoch: 0041 train cost= 3.141502507\n",
      "Epoch: 0046 train cost= 3.059525423\n",
      "Epoch: 0051 train cost= 2.978543582\n",
      "Epoch: 0056 train cost= 2.899726366\n",
      "Epoch: 0061 train cost= 2.822270789\n",
      "Epoch: 0066 train cost= 2.744826163\n",
      "Epoch: 0071 train cost= 2.669226631\n",
      "Epoch: 0076 train cost= 2.592958947\n",
      "Epoch: 0081 train cost= 2.516887579\n",
      "Epoch: 0086 train cost= 2.444070041\n",
      "Epoch: 0091 train cost= 2.371057842\n",
      "Epoch: 0096 train cost= 2.299650514\n",
      "Epoch: 0101 train cost= 2.227184163\n",
      "Epoch: 0106 train cost= 2.156400211\n",
      "Epoch: 0111 train cost= 2.083965830\n",
      "Epoch: 0116 train cost= 2.014614938\n",
      "Epoch: 0121 train cost= 1.945414134\n",
      "Epoch: 0126 train cost= 1.876466762\n",
      "Epoch: 0131 train cost= 1.808496328\n",
      "Epoch: 0136 train cost= 1.740880524\n",
      "Epoch: 0141 train cost= 1.675171798\n",
      "Epoch: 0146 train cost= 1.608764859\n",
      "Epoch: 0151 train cost= 1.544734341\n",
      "Epoch: 0156 train cost= 1.480167407\n",
      "Epoch: 0161 train cost= 1.418912650\n",
      "Epoch: 0166 train cost= 1.355510369\n",
      "Epoch: 0171 train cost= 1.294554134\n",
      "Epoch: 0176 train cost= 1.233998612\n",
      "Epoch: 0181 train cost= 1.177796840\n",
      "Epoch: 0186 train cost= 1.122031035\n",
      "Epoch: 0191 train cost= 1.067290822\n",
      "Epoch: 0196 train cost= 1.013507366\n",
      "Epoch: 0201 train cost= 0.961696168\n",
      "Epoch: 0206 train cost= 0.911950517\n",
      "Epoch: 0211 train cost= 0.866311164\n",
      "Epoch: 0216 train cost= 0.821857891\n",
      "Epoch: 0221 train cost= 0.783036659\n",
      "Epoch: 0226 train cost= 0.744745319\n",
      "Epoch: 0231 train cost= 0.711250501\n",
      "Epoch: 0236 train cost= 0.680024639\n",
      "Epoch: 0241 train cost= 0.653465961\n",
      "Epoch: 0246 train cost= 0.631183212\n",
      "Epoch: 0251 train cost= 0.615464452\n",
      "Epoch: 0256 train cost= 0.605290789\n",
      "Epoch: 0261 train cost= 0.595646878\n",
      "Epoch: 0266 train cost= 0.590839122\n",
      "Epoch: 0271 train cost= 0.585214758\n",
      "Epoch: 0276 train cost= 0.582117807\n",
      "Epoch: 0281 train cost= 0.578496649\n",
      "Epoch: 0286 train cost= 0.574731798\n",
      "Epoch: 0291 train cost= 0.570204456\n",
      "Epoch: 0296 train cost= 0.567761055\n",
      "Epoch: 0301 train cost= 0.565460840\n",
      "Epoch: 0306 train cost= 0.560719887\n",
      "Epoch: 0311 train cost= 0.556342092\n",
      "Epoch: 0316 train cost= 0.557251693\n",
      "Epoch: 0321 train cost= 0.551908336\n",
      "Epoch: 0326 train cost= 0.549742206\n",
      "Epoch: 0331 train cost= 0.545476629\n",
      "Epoch: 0336 train cost= 0.545033753\n",
      "Epoch: 0341 train cost= 0.543705905\n",
      "Epoch: 0346 train cost= 0.539602763\n",
      "Epoch: 0351 train cost= 0.537654451\n",
      "Epoch: 0356 train cost= 0.534281691\n",
      "Epoch: 0361 train cost= 0.532548546\n",
      "Epoch: 0366 train cost= 0.530062777\n",
      "Epoch: 0371 train cost= 0.529005429\n",
      "Epoch: 0376 train cost= 0.525367773\n",
      "Epoch: 0381 train cost= 0.524048180\n",
      "Epoch: 0386 train cost= 0.521799795\n",
      "Epoch: 0391 train cost= 0.520739653\n",
      "Epoch: 0396 train cost= 0.519948422\n",
      "Epoch: 0401 train cost= 0.518358604\n",
      "Epoch: 0406 train cost= 0.514189194\n",
      "Epoch: 0411 train cost= 0.512806821\n",
      "Epoch: 0416 train cost= 0.511749492\n",
      "Epoch: 0421 train cost= 0.509921314\n",
      "Epoch: 0426 train cost= 0.507880217\n",
      "Epoch: 0431 train cost= 0.505663898\n",
      "Epoch: 0436 train cost= 0.505086362\n",
      "Epoch: 0441 train cost= 0.503331498\n",
      "Epoch: 0446 train cost= 0.500922875\n",
      "Epoch: 0451 train cost= 0.500832720\n",
      "Epoch: 0456 train cost= 0.499218104\n",
      "Epoch: 0461 train cost= 0.497975056\n",
      "Epoch: 0466 train cost= 0.496589150\n",
      "Epoch: 0471 train cost= 0.494554367\n",
      "Epoch: 0476 train cost= 0.494835848\n",
      "Epoch: 0481 train cost= 0.490833599\n",
      "Epoch: 0486 train cost= 0.489282821\n",
      "Epoch: 0491 train cost= 0.489001065\n",
      "Epoch: 0496 train cost= 0.488190126\n",
      "Epoch: 0501 train cost= 0.488167043\n",
      "Epoch: 0506 train cost= 0.485486773\n",
      "Epoch: 0511 train cost= 0.485834844\n",
      "Epoch: 0516 train cost= 0.484974494\n",
      "Epoch: 0521 train cost= 0.482067072\n",
      "Epoch: 0526 train cost= 0.482313053\n",
      "Epoch: 0531 train cost= 0.481179240\n",
      "Epoch: 0536 train cost= 0.477442883\n",
      "Epoch: 0541 train cost= 0.478913898\n",
      "Epoch: 0546 train cost= 0.476591984\n",
      "Epoch: 0551 train cost= 0.474739466\n",
      "Epoch: 0556 train cost= 0.473142247\n",
      "Epoch: 0561 train cost= 0.473772089\n",
      "Epoch: 0566 train cost= 0.472294226\n",
      "Epoch: 0571 train cost= 0.471104530\n",
      "Epoch: 0576 train cost= 0.472193892\n",
      "Epoch: 0581 train cost= 0.469612982\n",
      "Epoch: 0586 train cost= 0.468826738\n",
      "Epoch: 0591 train cost= 0.466975054\n",
      "Epoch: 0596 train cost= 0.467605726\n",
      "Optimization Finished!\n",
      "Un-matched: w_0:0\n",
      "Un-matched: b_0:0\n",
      "Un-matched: w_h_0:0\n",
      "Un-matched: b_h_0:0\n",
      "Un-matched: beta_a_0:0\n",
      "Un-matched: beta_b_0:0\n",
      "test acc: 0.9492800235748291\n",
      "0.00, 0.9485084\n",
      "0.05, 0.94862145\n",
      "0.10, 0.94889975\n",
      "0.15, 0.9485901\n",
      "0.20, 0.9485866\n",
      "0.25, 0.9488578\n",
      "0.30, 0.94849503\n",
      "0.35, 0.94904125\n",
      "0.40, 0.9488679\n",
      "0.45, 0.949207\n",
      "0.50, 0.9490159\n",
      "0.55, 0.94889575\n",
      "0.60, 0.9488624\n",
      "0.65, 0.94864476\n",
      "0.70, 0.948549\n",
      "0.75, 0.9484289\n",
      "0.80, 0.9486076\n",
      "0.85, 0.9476606\n",
      "0.90, 0.9338832\n",
      "0.95, 0.8540915\n",
      "0.98, 0.5555833\n",
      "0.99, 0.3118617\n",
      "1.00, 0.11462419\n",
      "0.00, 0.9488575\n",
      "0.05, 0.9489974\n",
      "0.10, 0.9486396\n",
      "0.15, 0.9486948\n",
      "0.20, 0.9485712\n",
      "0.25, 0.94869995\n",
      "0.30, 0.9486472\n",
      "0.35, 0.94877356\n",
      "0.40, 0.9488665\n",
      "0.45, 0.9488571\n",
      "0.50, 0.9484102\n",
      "0.55, 0.94855726\n",
      "0.60, 0.94869936\n",
      "0.65, 0.94864607\n",
      "0.70, 0.94887704\n",
      "0.75, 0.94884956\n",
      "0.80, 0.94849473\n",
      "0.85, 0.9482911\n",
      "0.90, 0.9465933\n",
      "0.95, 0.9260809\n",
      "0.98, 0.7948118\n",
      "0.99, 0.4994409\n",
      "1.00, 0.09896371\n"
     ]
    }
   ],
   "source": [
    "hidden_size = [100]\n",
    "batch_size = 128\n",
    "no_epochs = 600\n",
    "ANNEAL_RATE=0.000\n",
    "MIN_TEMP=0.1\n",
    "\n",
    "tf.set_random_seed(12)\n",
    "np.random.seed(1)\n",
    "\n",
    "ibp_acc = np.array([])\n",
    "\n",
    "coreset_size = 0\n",
    "data_gen = MnistGenerator()\n",
    "single_head=False\n",
    "in_dim, out_dim = data_gen.get_dims()\n",
    "x_testsets, y_testsets = [], []\n",
    "task_id=0\n",
    "    \n",
    "tf.reset_default_graph()  \n",
    "x_train, y_train, x_test, y_test = data_gen.task()\n",
    "x_testsets.append(x_test)\n",
    "y_testsets.append(y_test)\n",
    "\n",
    "# Set the readout head to train\n",
    "head = 0 if single_head else task_id\n",
    "bsize = x_train.shape[0] if (batch_size is None) else batch_size\n",
    "\n",
    "# Train network with maximum likelihood to initialize first model\n",
    "if task_id == 0:\n",
    "    ml_model = Vanilla_NN(in_dim, hidden_size, out_dim, x_train.shape[0])\n",
    "    ml_model.train(x_train, y_train, task_id, 100, bsize)\n",
    "    mf_weights = ml_model.get_weights()\n",
    "    mf_variances = None\n",
    "    mf_betas = None\n",
    "    ml_model.close_session()\n",
    "\n",
    "# Train on non-coreset data\n",
    "mf_model = MFVI_IBP_NN_prune(in_dim, hidden_size, out_dim, x_train.shape[0], \n",
    "                             num_ibp_samples=10, prev_means=mf_weights, \n",
    "                       prev_log_variances=mf_variances, prev_betas=mf_betas,alpha0=5.0, beta0=1.0,\n",
    "                       learning_rate=0.00005, lambda_1=1.0, lambda_2=1.0, no_pred_samples=100,\n",
    "                       name='ibp_wp_mnist_new')\n",
    "\n",
    "#mf_model.restore(os.path.join(\"logs\", \"graph_{}_task{}\".format('ibp_wp_mnist', 0)))\n",
    "mf_model.train(x_train, y_train, head, no_epochs, bsize,\n",
    "              anneal_rate=ANNEAL_RATE, min_temp=MIN_TEMP)\n",
    "\n",
    "xs, ya_ibp, yb_ibp  = mf_model.prune_weights(x_test, y_test, head)\n",
    "\n",
    "mf_model.close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(xs, ya, label='$|\\mu|$')\n",
    "#plt.plot(xs, yb, label='snr')\n",
    "plt.plot(xs, ya_ibp, label='ibp $|\\mu|$')\n",
    "plt.plot(xs, yb_ibp, label='ibp snr')\n",
    "plt.xlabel('cut-off')\n",
    "plt.ylabel('acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No IBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFVI_NN_prune(MFVI_NN):\n",
    "    def __init__(self, input_size, hidden_size, output_size, training_size, \n",
    "        no_train_samples=10, no_pred_samples=100, prev_means=None, prev_log_variances=None, learning_rate=0.001, \n",
    "        prior_mean=0, prior_var=1):\n",
    "\n",
    "        super(MFVI_NN_prune, self).__init__(input_size, hidden_size, output_size, training_size, \n",
    "        no_train_samples, no_pred_samples, prev_means, prev_log_variances, learning_rate, \n",
    "        prior_mean, prior_var)\n",
    "\n",
    "\n",
    "    def prune_weights(self, X_test, Y_test, task_id):\n",
    "        \"\"\" Performs weight pruning.\n",
    "        \n",
    "        Z is at a data level doesn't make sense to introduce this intot he mask over weights which get zeroed \n",
    "        out. Simlpy running the accuracy over the graph will entail that Z is incorporated into the \n",
    "        matrix math for the prediction calculations.\n",
    "        \n",
    "        Args:\n",
    "            X_test: numpy array\n",
    "            Y_test: numpy array\n",
    "            task_id: int\n",
    "        :return: cutoffs, accs via naive pruning, accs via snr pruning,\n",
    "        weight values, sigma values of network\n",
    "        \"\"\"\n",
    "\n",
    "        def reset_weights(pr_mus, pr_sigmas, _mus, _sigmas):\n",
    "            \"\"\" Reset weights of graph to original values\n",
    "            Args:\n",
    "                pr_mus: list of tf variables which have been pruned\n",
    "                pr_sigmas: list of tf variables which have been pruned\n",
    "                _mus: list of cached mus in numpy\n",
    "                _sigmas: list of cached sigmas in numpy\n",
    "            \"\"\"\n",
    "\n",
    "            for v, _v in zip(pr_mus, _mus):\n",
    "                self.sess.run(tf.assign(v, tf.cast(_v, v.dtype)))\n",
    "\n",
    "            for v, _v in zip(pr_sigmas, _sigmas):\n",
    "                self.sess.run(tf.assign(v, tf.cast(_v, v.dtype)))\n",
    "\n",
    "        def pruning(remove_pct, weightvalues, sigmavalues,\n",
    "                    weights, sigmas, uncert_pruning=True):\n",
    "            \"\"\" Performs weight pruning experiment\n",
    "            Args:\n",
    "                weightvalues: np array of weights\n",
    "                sigmavalues: np array of sigmas\n",
    "                weights: list of tf weight variable\n",
    "                sigmas: list of tf sigma variables\n",
    "                uncert_pruning: bool pruning by snr\n",
    "            \"\"\"\n",
    "            if uncert_pruning:\n",
    "                sorted_STN = np.sort(np.abs(weightvalues) / sigmavalues)\n",
    "                \n",
    "            else:\n",
    "                sorted_STN = np.sort(np.abs(weightvalues))\n",
    "            cutoff = sorted_STN[int(remove_pct * len(sorted_STN))]\n",
    "            \n",
    "            # Weights, biases and head weights\n",
    "            for v, s in zip(weights, sigmas):\n",
    "                if uncert_pruning:\n",
    "                    snr = tf.abs(v) / tf.exp(0.5*s)\n",
    "                    mask = tf.greater_equal(snr, cutoff)\n",
    "                else:\n",
    "                    mask = tf.greater_equal(tf.abs(v), cutoff)\n",
    "                self.sess.run(tf.assign(v, tf.multiply(v, tf.cast(mask, v.dtype))))\n",
    "                \n",
    "            accs = []\n",
    "            for _ in range(10):\n",
    "                accs.append(self.sess.run(self.acc, {self.x: X_test,\n",
    "                                                     self.y: Y_test,\n",
    "                                                     self.task_idx: task_id}))\n",
    "            print(\"%.2f, %s\" % (np.sum(sorted_STN < cutoff) / len(sorted_STN), np.mean(accs)))\n",
    "            return np.mean(accs)\n",
    "\n",
    "        # get weights\n",
    "        weights = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=tf.get_variable_scope().name)\n",
    "        \n",
    "        # Get weights from network\n",
    "        mus_w = []\n",
    "        mus_b = []\n",
    "        sigmas_w = []\n",
    "        sigmas_b = []\n",
    "        mus_h = [] # weights and biases\n",
    "        sigmas_h = [] # weights and biases\n",
    "        for v in weights:\n",
    "            if re.match(\"^([w])(_mu_)([0-9]+)(:0)$\", v.name):\n",
    "                mus_w.append(v)\n",
    "            elif re.match(\"^([w])(_sigma_)([0-9]+)(:0)$\", v.name):\n",
    "                sigmas_w.append(v)\n",
    "            elif re.match(\"^([b])(_mu_)([0-9]+)(:0)$\", v.name):\n",
    "                mus_b.append(v)\n",
    "            elif re.match(\"^([b])(_sigma_)([0-9]+)(:0)$\", v.name):\n",
    "                sigmas_b.append(v)\n",
    "            elif re.match(\"^([wb])(_mu_h_)([0-9]+)(:0)$\", v.name):\n",
    "                mus_h.append(v)\n",
    "            elif re.match(\"^([wb])(_sigma_h_)([0-9]+)(:0)$\", v.name):\n",
    "                sigmas_h.append(v)\n",
    "            else:\n",
    "                print(\"Un-matched: {}\".format(v.name))\n",
    "                \n",
    "        # cache network weights of resetting the network\n",
    "        _mus_w = [self.sess.run(w) for w in mus_w]\n",
    "        _sigmas_w = [self.sess.run(w) for w in sigmas_w]\n",
    "        _mus_b = [self.sess.run(w) for w in mus_b]\n",
    "        _sigmas_b = [self.sess.run(w) for w in sigmas_b]\n",
    "        _mus_h = [self.sess.run(w) for w in mus_h]\n",
    "        _sigmas_h = [self.sess.run(w) for w in sigmas_h]\n",
    "        \n",
    "        weightvalues = np.hstack(np.array([self.sess.run(w).flatten() for w in mus_w + mus_b + mus_h]))\n",
    "        sigmavalues = np.hstack(np.array([self.sess.run(tf.exp(0.5*s)).flatten() for s in sigmas_w + sigmas_b + sigmas_h]))\n",
    "    \n",
    "        xs = np.append(0.05 * np.array(range(20)), np.array([0.98, 0.99, 0.999]))\n",
    "        # pruning\n",
    "        ya = []\n",
    "        for pct in xs:\n",
    "            ya_ibp.append(pruning(pct, weightvalues, sigmavalues, mus_w + mus_b + mus_h,\n",
    "                              sigmas_w + sigmas_b + sigmas_h, uncert_pruning=False))\n",
    "\n",
    "        # reset etc.\n",
    "        reset_weights(mus_w, sigmas_w, _mus_w, _sigmas_w)\n",
    "        reset_weights(mus_b, sigmas_b, _mus_b, _sigmas_b)\n",
    "        reset_weights(mus_h, sigmas_h, _mus_h, _sigmas_h)\n",
    "        yb = []\n",
    "        for pct in xs:\n",
    "            yb_ibp.append(pruning(pct, weightvalues, sigmavalues, mus_w + mus_b + mus_h,\n",
    "                                  sigmas_w + sigmas_b + sigmas_h, uncert_pruning=True))\n",
    "            \n",
    "        reset_weights(mus_w, sigmas_w, _mus_w, _sigmas_w)\n",
    "        reset_weights(mus_b, sigmas_b, _mus_b, _sigmas_b)\n",
    "        reset_weights(mus_h, sigmas_h, _mus_h, _sigmas_h)\n",
    "        \n",
    "        return xs, ya, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.423908216\n",
      "Epoch: 0006 cost= 0.074809015\n",
      "Epoch: 0011 cost= 0.034873054\n",
      "Epoch: 0016 cost= 0.017029525\n",
      "Epoch: 0021 cost= 0.008828043\n",
      "Epoch: 0026 cost= 0.005183751\n",
      "Epoch: 0031 cost= 0.004760422\n",
      "Epoch: 0036 cost= 0.000991851\n",
      "Epoch: 0041 cost= 0.000453620\n",
      "Epoch: 0046 cost= 0.001089015\n",
      "Epoch: 0051 cost= 0.000240368\n",
      "Epoch: 0056 cost= 0.000249355\n",
      "Epoch: 0061 cost= 0.000135572\n",
      "Epoch: 0066 cost= 0.011170367\n",
      "Epoch: 0071 cost= 0.000105972\n",
      "Epoch: 0076 cost= 0.000064127\n",
      "Epoch: 0081 cost= 0.000742145\n",
      "Epoch: 0086 cost= 0.000067122\n",
      "Epoch: 0091 cost= 0.000039976\n",
      "Epoch: 0096 cost= 0.003797296\n",
      "Optimization Finished!\n",
      "Epoch: 0001 cost= 3.228416839\n",
      "Epoch: 0006 cost= 2.006878323\n",
      "Epoch: 0011 cost= 1.208152405\n",
      "Epoch: 0016 cost= 0.899522673\n",
      "Epoch: 0021 cost= 0.783278817\n",
      "Epoch: 0026 cost= 0.700111097\n",
      "Epoch: 0031 cost= 0.634223401\n",
      "Epoch: 0036 cost= 0.581039405\n",
      "Epoch: 0041 cost= 0.532690271\n",
      "Epoch: 0046 cost= 0.493331300\n",
      "Epoch: 0051 cost= 0.460849917\n",
      "Epoch: 0056 cost= 0.432339303\n",
      "Epoch: 0061 cost= 0.407290286\n",
      "Epoch: 0066 cost= 0.385844985\n",
      "Epoch: 0071 cost= 0.367086217\n",
      "Epoch: 0076 cost= 0.351761799\n",
      "Epoch: 0081 cost= 0.336908039\n",
      "Epoch: 0086 cost= 0.326290261\n",
      "Epoch: 0091 cost= 0.317135899\n",
      "Epoch: 0096 cost= 0.308558462\n",
      "Epoch: 0101 cost= 0.302854873\n",
      "Epoch: 0106 cost= 0.297494745\n",
      "Epoch: 0111 cost= 0.292592399\n",
      "Epoch: 0116 cost= 0.290042144\n",
      "Epoch: 0121 cost= 0.286611462\n",
      "Epoch: 0126 cost= 0.283784523\n",
      "Epoch: 0131 cost= 0.282957681\n",
      "Epoch: 0136 cost= 0.279739034\n",
      "Epoch: 0141 cost= 0.277938983\n",
      "Epoch: 0146 cost= 0.276961154\n",
      "Epoch: 0151 cost= 0.274667143\n",
      "Epoch: 0156 cost= 0.274613926\n",
      "Epoch: 0161 cost= 0.273212079\n",
      "Epoch: 0166 cost= 0.272973476\n",
      "Epoch: 0171 cost= 0.271645905\n",
      "Epoch: 0176 cost= 0.271362239\n",
      "Epoch: 0181 cost= 0.271024957\n",
      "Epoch: 0186 cost= 0.270412340\n",
      "Epoch: 0191 cost= 0.269200906\n",
      "Epoch: 0196 cost= 0.268814857\n",
      "Epoch: 0201 cost= 0.268044317\n",
      "Epoch: 0206 cost= 0.267593539\n",
      "Epoch: 0211 cost= 0.267146134\n",
      "Epoch: 0216 cost= 0.266896738\n",
      "Epoch: 0221 cost= 0.266871759\n",
      "Epoch: 0226 cost= 0.266572029\n",
      "Epoch: 0231 cost= 0.266282642\n",
      "Epoch: 0236 cost= 0.266497814\n",
      "Epoch: 0241 cost= 0.265445035\n",
      "Epoch: 0246 cost= 0.265247260\n",
      "Epoch: 0251 cost= 0.265196222\n",
      "Epoch: 0256 cost= 0.264387001\n",
      "Epoch: 0261 cost= 0.264067636\n",
      "Epoch: 0266 cost= 0.263750414\n",
      "Epoch: 0271 cost= 0.263873744\n",
      "Epoch: 0276 cost= 0.263147304\n",
      "Epoch: 0281 cost= 0.262658606\n",
      "Epoch: 0286 cost= 0.262500711\n",
      "Epoch: 0291 cost= 0.262018001\n",
      "Epoch: 0296 cost= 0.262106352\n",
      "Epoch: 0301 cost= 0.262409373\n",
      "Epoch: 0306 cost= 0.261281542\n",
      "Epoch: 0311 cost= 0.260574455\n",
      "Epoch: 0316 cost= 0.261507865\n",
      "Epoch: 0321 cost= 0.260857962\n",
      "Epoch: 0326 cost= 0.260022441\n",
      "Epoch: 0331 cost= 0.260935020\n",
      "Epoch: 0336 cost= 0.261141546\n",
      "Epoch: 0341 cost= 0.260662476\n",
      "Epoch: 0346 cost= 0.260514371\n",
      "Epoch: 0351 cost= 0.259707072\n",
      "Epoch: 0356 cost= 0.260273881\n",
      "Epoch: 0361 cost= 0.258683867\n",
      "Epoch: 0366 cost= 0.259598982\n",
      "Epoch: 0371 cost= 0.260145604\n",
      "Epoch: 0376 cost= 0.259473826\n",
      "Epoch: 0381 cost= 0.259386688\n",
      "Epoch: 0386 cost= 0.259709292\n",
      "Epoch: 0391 cost= 0.259159913\n",
      "Epoch: 0396 cost= 0.258364240\n",
      "Epoch: 0401 cost= 0.259011798\n",
      "Epoch: 0406 cost= 0.258531249\n",
      "Epoch: 0411 cost= 0.259322110\n",
      "Epoch: 0416 cost= 0.260322512\n",
      "Epoch: 0421 cost= 0.258033792\n",
      "Epoch: 0426 cost= 0.259382425\n",
      "Epoch: 0431 cost= 0.258836595\n",
      "Epoch: 0436 cost= 0.258889246\n",
      "Epoch: 0441 cost= 0.257995166\n",
      "Epoch: 0446 cost= 0.258114540\n",
      "Epoch: 0451 cost= 0.258641413\n",
      "Epoch: 0456 cost= 0.258252315\n",
      "Epoch: 0461 cost= 0.257014346\n",
      "Epoch: 0466 cost= 0.257930188\n",
      "Epoch: 0471 cost= 0.257308934\n",
      "Epoch: 0476 cost= 0.258296134\n",
      "Epoch: 0481 cost= 0.257049796\n",
      "Epoch: 0486 cost= 0.256496205\n",
      "Epoch: 0491 cost= 0.257005194\n",
      "Epoch: 0496 cost= 0.258145744\n",
      "Optimization Finished!\n",
      "Un-matched: w_0:0\n",
      "Un-matched: b_0:0\n",
      "Un-matched: w_h_0:0\n",
      "Un-matched: b_h_0:0\n",
      "0.00, 0.96247864\n",
      "0.05, 0.9627081\n",
      "0.10, 0.96253884\n",
      "0.15, 0.9625432\n",
      "0.20, 0.9623867\n",
      "0.25, 0.9627093\n",
      "0.30, 0.96240246\n",
      "0.35, 0.9625004\n",
      "0.40, 0.9619547\n",
      "0.45, 0.957757\n",
      "0.50, 0.94896907\n",
      "0.55, 0.9112841\n",
      "0.60, 0.7925558\n",
      "0.65, 0.6456682\n",
      "0.70, 0.4496879\n",
      "0.75, 0.3047071\n",
      "0.80, 0.23842987\n",
      "0.85, 0.1298538\n",
      "0.90, 0.1084046\n",
      "0.95, 0.098711506\n",
      "0.98, 0.099089004\n",
      "0.99, 0.0976184\n",
      "1.00, 0.0974261\n",
      "0.00, 0.96249884\n",
      "0.05, 0.9623512\n",
      "0.10, 0.96267366\n",
      "0.15, 0.96253574\n",
      "0.20, 0.96257305\n",
      "0.25, 0.9625788\n",
      "0.30, 0.962557\n",
      "0.35, 0.9625977\n",
      "0.40, 0.962444\n",
      "0.45, 0.9623726\n",
      "0.50, 0.96228063\n",
      "0.55, 0.9622771\n",
      "0.60, 0.96195334\n",
      "0.65, 0.9605943\n",
      "0.70, 0.9545126\n",
      "0.75, 0.9228345\n",
      "0.80, 0.7808744\n",
      "0.85, 0.4288025\n",
      "0.90, 0.22955501\n",
      "0.95, 0.2124244\n",
      "0.98, 0.1555762\n",
      "0.99, 0.1274483\n",
      "1.00, 0.1004287\n"
     ]
    }
   ],
   "source": [
    "hidden_size = [100]\n",
    "batch_size = 128\n",
    "no_epochs = 500\n",
    "\n",
    "tf.set_random_seed(12)\n",
    "np.random.seed(1)\n",
    "\n",
    "coreset_size = 0\n",
    "data_gen = MnistGenerator()\n",
    "single_head=False\n",
    "in_dim, out_dim = data_gen.get_dims()\n",
    "x_testsets, y_testsets = [], []\n",
    "task_id=0\n",
    "    \n",
    "tf.reset_default_graph()  \n",
    "x_train, y_train, x_test, y_test = data_gen.task()\n",
    "x_testsets.append(x_test)\n",
    "y_testsets.append(y_test)\n",
    "\n",
    "# Set the readout head to train\n",
    "head = 0 if single_head else task_id\n",
    "bsize = x_train.shape[0] if (batch_size is None) else batch_size\n",
    "\n",
    "# Train network with maximum likelihood to initialize first model\n",
    "if task_id == 0:\n",
    "    ml_model = Vanilla_NN(in_dim, hidden_size, out_dim, x_train.shape[0])\n",
    "    ml_model.train(x_train, y_train, task_id, 100, bsize)\n",
    "    mf_weights = ml_model.get_weights()\n",
    "    mf_variances = None\n",
    "    ml_model.close_session()\n",
    "\n",
    "# Train on non-coreset data\n",
    "mf_model = MFVI_NN_prune(in_dim, hidden_size, out_dim, x_train.shape[0], prev_means=mf_weights, \n",
    "                         prev_log_variances=mf_variances)\n",
    "\n",
    "mf_model.train(x_train, y_train, head, no_epochs, bsize)\n",
    "\n",
    "xs, ya, yb  = mf_model.prune_weights(x_test, y_test, head)\n",
    "\n",
    "mf_model.close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ya = ya_ibp[len(xs):]\n",
    "yb = yb_ibp[len(xs):]\n",
    "ya_ibp = ya_ibp[:len(xs)]\n",
    "yb_ibp = yb_ibp[:len(xs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(xs, ya, label='$|\\mu|$')\n",
    "plt.plot(xs, yb, label='snr')\n",
    "plt.plot(xs, ya_ibp, label='ibp $|\\mu|$')\n",
    "plt.plot(xs, yb_ibp, label='ibp snr')\n",
    "plt.xlabel('cut-off')\n",
    "plt.ylabel('acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/weight_pruning.pkl', 'wb') as input_file:\n",
    "    pickle.dump({'ya_nnvi': ya,\n",
    "                 'yb_nnvi': yb,\n",
    "                 'ya_ibp': ya_ibp,\n",
    "                 'yb_ibp': yb_ibp}, input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = [100]\n",
    "batch_size = 128\n",
    "no_epochs = 200\n",
    "alpha0 = 1.0\n",
    "tau0=1.0 # initial temperature\n",
    "ANNEAL_RATE=0.000\n",
    "MIN_TEMP=0.1\n",
    "\n",
    "tf.set_random_seed(12)\n",
    "np.random.seed(1)\n",
    "\n",
    "ibp_acc = np.array([])\n",
    "\n",
    "coreset_size = 0\n",
    "val = False\n",
    "data_gen = SplitMnistGenerator(val, num_tasks=1)\n",
    "single_head=False\n",
    "in_dim, out_dim = data_gen.get_dims()\n",
    "x_testsets, y_testsets = [], []\n",
    "x_valsets, y_valsets = [], []\n",
    "for task_id in range(data_gen.max_iter):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    if val:\n",
    "        x_train, y_train, x_test, y_test, x_val, y_val = data_gen.next_task()\n",
    "        x_valsets.append(x_val)\n",
    "        y_valsets.append(y_val)\n",
    "    else:    \n",
    "        x_train, y_train, x_test, y_test = data_gen.next_task()\n",
    "    x_testsets.append(x_test)\n",
    "    y_testsets.append(y_test)\n",
    "\n",
    "    # Set the readout head to train\n",
    "    head = 0 if single_head else task_id\n",
    "    bsize = x_train.shape[0] if (batch_size is None) else batch_size\n",
    "    \n",
    "    # Train network with maximum likelihood to initialize first model\n",
    "    if task_id == 0:\n",
    "        ml_model = Vanilla_NN(in_dim, hidden_size, out_dim, x_train.shape[0])\n",
    "        ml_model.train(x_train, y_train, task_id, 100, bsize)\n",
    "        mf_weights = ml_model.get_weights()\n",
    "        mf_variances = None\n",
    "        mf_betas = None\n",
    "        ml_model.close_session()\n",
    "\n",
    "    # Train on non-coreset data\n",
    "    mf_model = MFVI_IBP_NN_prune(in_dim, hidden_size, out_dim, x_train.shape[0], prev_means=mf_weights, \n",
    "                           prev_log_variances=mf_variances, prev_betas=mf_betas,alpha0=alpha0,\n",
    "                           learning_rate=0.01, lambda_1=tau0, lambda_2=1.0, no_pred_samples=100)\n",
    "    mf_model.train(x_train, y_train, head, no_epochs, bsize,\n",
    "                   anneal_rate=ANNEAL_RATE, min_temp=MIN_TEMP)\n",
    "    \n",
    "    xs, ya, yb, ya_ibp, yb_ibp  = mf_model.prune_weights(x_test, y_test, head)\n",
    "    \n",
    "    mf_model.close_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
