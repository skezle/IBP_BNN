{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0819 17:30:21.492286 140008901007168 deprecation_wrapper.py:119] From /home/skessler/Projects/IBP_BNN/ddm/alg/cla_models_multihead.py:9: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0819 17:30:21.493005 140008901007168 deprecation_wrapper.py:119] From /home/skessler/Projects/IBP_BNN/ddm/alg/cla_models_multihead.py:13: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gzip\n",
    "import pickle\n",
    "import sys\n",
    "import copy\n",
    "import os.path\n",
    "import pdb\n",
    "import re\n",
    "from ddm.run_split import SplitMnistGenerator\n",
    "from ddm.alg.cla_models_multihead import MFVI_IBP_NN, Vanilla_NN\n",
    "from ddm.alg.utils import get_scores, concatenate_results\n",
    "from ddm.alg.vcl import run_vcl\n",
    "from copy import deepcopy\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBP network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0817 10:52:12.129490 140686037821248 deprecation_wrapper.py:119] From /home/skessler/Projects/IBP_BNN/ddm/alg/cla_models_multihead.py:56: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0817 10:52:12.132290 140686037821248 deprecation_wrapper.py:119] From /home/skessler/Projects/IBP_BNN/ddm/alg/cla_models_multihead.py:167: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0817 10:52:12.188359 140686037821248 deprecation_wrapper.py:119] From /home/skessler/Projects/IBP_BNN/ddm/alg/cla_models_multihead.py:61: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0817 10:52:12.303390 140686037821248 deprecation_wrapper.py:119] From /home/skessler/Projects/IBP_BNN/ddm/alg/cla_models_multihead.py:65: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.049326868\n",
      "Epoch: 0006 cost= 0.000994026\n",
      "Epoch: 0011 cost= 0.000234237\n",
      "Epoch: 0016 cost= 0.000100588\n",
      "Epoch: 0021 cost= 0.000055076\n",
      "Epoch: 0026 cost= 0.000033257\n",
      "Epoch: 0031 cost= 0.000021853\n",
      "Epoch: 0036 cost= 0.000014344\n",
      "Epoch: 0041 cost= 0.000010315\n",
      "Epoch: 0046 cost= 0.000007250\n",
      "Epoch: 0051 cost= 0.000005240\n",
      "Epoch: 0056 cost= 0.000003922\n",
      "Epoch: 0061 cost= 0.000002916\n",
      "Epoch: 0066 cost= 0.000002214\n",
      "Epoch: 0071 cost= 0.000001703\n",
      "Epoch: 0076 cost= 0.000001282\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9d3b4377aeb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtask_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mml_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVanilla_NN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mml_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mmf_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mml_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mmf_variances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/IBP_BNN/ddm/alg/cla_models_multihead.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, y_train, task_idx, no_epochs, batch_size, display_epoch)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mperm_inds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperm_inds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mcur_x_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm_inds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0mcur_y_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm_inds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = [100]\n",
    "batch_size = 128\n",
    "no_epochs = 100\n",
    "alpha0 = 1.0\n",
    "tau0=1.0 # initial temperature\n",
    "ANNEAL_RATE=0.000\n",
    "MIN_TEMP=0.1\n",
    "\n",
    "# Run vanilla VCL\n",
    "tf.set_random_seed(12)\n",
    "np.random.seed(1)\n",
    "\n",
    "ibp_acc = np.array([])\n",
    "\n",
    "coreset_size = 0\n",
    "val = True\n",
    "data_gen = SplitMnistGenerator(val)\n",
    "single_head=False\n",
    "in_dim, out_dim = data_gen.get_dims()\n",
    "x_testsets, y_testsets = [], []\n",
    "x_valsets, y_valsets = [], []\n",
    "for task_id in range(data_gen.max_iter):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    if val:\n",
    "        x_train, y_train, x_test, y_test, x_val, y_val = data_gen.next_task()\n",
    "        x_valsets.append(x_val)\n",
    "        y_valsets.append(y_val)\n",
    "    else:    \n",
    "        x_train, y_train, x_test, y_test = data_gen.next_task()\n",
    "    x_testsets.append(x_test)\n",
    "    y_testsets.append(y_test)\n",
    "\n",
    "    # Set the readout head to train\n",
    "    head = 0 if single_head else task_id\n",
    "    bsize = x_train.shape[0] if (batch_size is None) else batch_size\n",
    "    \n",
    "    # Train network with maximum likelihood to initialize first model\n",
    "    if task_id == 0:\n",
    "        ml_model = Vanilla_NN(in_dim, hidden_size, out_dim, x_train.shape[0])\n",
    "        ml_model.train(x_train, y_train, task_id, no_epochs, bsize)\n",
    "        mf_weights = ml_model.get_weights()\n",
    "        mf_variances = None\n",
    "        mf_betas = None\n",
    "        ml_model.close_session()\n",
    "\n",
    "    # Train on non-coreset data\n",
    "    mf_model = MFVI_IBP_NN(in_dim, hidden_size, out_dim, x_train.shape[0], prev_means=mf_weights, \n",
    "                           prev_log_variances=mf_variances, prev_betas=mf_betas,alpha0=alpha0,\n",
    "                           learning_rate=0.01, temp=tau0, temp_prior=1.0, no_pred_samples=100)\n",
    "    mf_model.train(x_train, y_train, head, no_epochs, bsize,\n",
    "                   anneal_rate=ANNEAL_RATE, min_temp=MIN_TEMP)\n",
    "    mf_weights, mf_variances, mf_betas = mf_model.get_weights()\n",
    "\n",
    "    acc = get_scores(mf_model, x_valsets, y_valsets, single_head)\n",
    "    ibp_acc = concatenate_results(acc, ibp_acc)\n",
    "    \n",
    "    mf_model.close_session()\n",
    "    \n",
    "ibp_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Vanilla VCL\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(12)\n",
    "np.random.seed(1)\n",
    "hidden_size = [10]\n",
    "coreset_size = 0\n",
    "\n",
    "data_gen = SplitMnistGenerator()\n",
    "vcl_result = run_vcl(hidden_size, no_epochs, data_gen, \n",
    "                              lambda a: a, coreset_size, batch_size, single_head)\n",
    "print(vcl_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run IBP VCL\n",
    "# tf.reset_default_graph()\n",
    "# tf.set_random_seed(12)\n",
    "# np.random.seed(1)\n",
    "# coreset_size = 0\n",
    "\n",
    "# hidden_size = [50]\n",
    "# batch_size = 128\n",
    "# no_epochs = 100\n",
    "# alpha0 = 5.0\n",
    "# tau0=0.1 # initial temperature\n",
    "# temp_prior=1.0\n",
    "# ANNEAL_RATE=0.000\n",
    "# MIN_TEMP=0.1\n",
    "# single_head=False\n",
    "\n",
    "# # data_gen = SplitMnistGenerator()\n",
    "# # vcl_ibp_result = vcl.run_vcl_ibp(hidden_size=hidden_size, no_epochs=no_epochs, data_gen=data_gen,\n",
    "# #                                   batch_size=batch_size, single_head=single_head, alpha0=alpha0,\n",
    "# #                                   learning_rate=0.01, temp_prior=temp_prior, no_pred_samples=100,\n",
    "# #                                   tau0=tau0, tau_anneal_rate=ANNEAL_RATE, tau_min=MIN_TEMP)\n",
    "# # print(vcl_ibp_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ibp_acc = np.nanmean(ibp_acc, 1)\n",
    "_vcl_result = np.nanmean(vcl_result, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_vcl_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=True)\n",
    "#plt.rc('font', family='serif')\n",
    "\n",
    "fig = plt.figure(figsize=(7,3))\n",
    "ax = plt.gca()\n",
    "plt.plot(np.arange(len(_ibp_acc))+1, _ibp_acc, label='VCL + IBP', marker='o')\n",
    "plt.plot(np.arange(len(_vcl_result))+1, _vcl_result, label='VCL', marker='o')\n",
    "ax.set_xticks(range(1, len(_ibp_acc)+1))\n",
    "ax.set_ylabel('Average accuracy')\n",
    "ax.set_xlabel('\\# tasks')\n",
    "ax.legend()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFVI_IBP_NN_prune(MFVI_IBP_NN):\n",
    "    def __init__(self, input_size, hidden_size, output_size, training_size,\n",
    "                 no_train_samples=10, no_pred_samples=100, prev_means=None, prev_log_variances=None,\n",
    "                 prev_betas=None, learning_rate=0.001,\n",
    "                 prior_mean=0, prior_var=1, alpha0=5., beta0=1., lambda_1=1., lambda_2=1.,\n",
    "                 tensorboard_dir='logs', name='ibp_wp', min_temp=0.5, tb_logging=True,\n",
    "                output_tb_gradients=True):\n",
    "\n",
    "        super(MFVI_IBP_NN_prune, self).__init__(input_size, hidden_size, output_size, training_size,\n",
    "                 no_train_samples, no_pred_samples, prev_means, prev_log_variances,\n",
    "                 prev_betas, learning_rate,\n",
    "                 prior_mean, prior_var, alpha0, beta0, lambda_1, lambda_2,\n",
    "                 tensorboard_dir, name, min_temp, tb_logging, output_tb_gradients=True)\n",
    "\n",
    "\n",
    "    def prune_weights(self, X_test, Y_test, task_id):\n",
    "        \"\"\" Performs weight pruning\n",
    "        Args:\n",
    "            X_test: numpy array\n",
    "            Y_test: numpy array\n",
    "            task_id: int\n",
    "        :return: cutoffs, accs via naive pruning, accs via snr pruning,\n",
    "        weight values, sigma values of network\n",
    "        \"\"\"\n",
    "\n",
    "        def reset_weights(pr_mus, pr_sigmas, _mus, _sigmas):\n",
    "            \"\"\" Reset weights of graph to original values\n",
    "            Args:\n",
    "                pr_mus: list of tf variables which have been pruned\n",
    "                pr_sigmas: list of tf variables which have been pruned\n",
    "                _mus: list of cached mus in numpy\n",
    "                _sigmas: list of cached sigmas in numpy\n",
    "            \"\"\"\n",
    "\n",
    "            for v, _v in zip(pr_mus, _mus):\n",
    "                self.sess.run(tf.assign(v, tf.cast(_v, v.dtype)))\n",
    "\n",
    "            for v, _v in zip(pr_sigmas, _sigmas):\n",
    "                self.sess.run(tf.assign(v, tf.cast(_v, v.dtype)))\n",
    "\n",
    "        def pruning(remove_pct, weightvalues_ibp, weightvalues, sigmavalues,\n",
    "                    weights, sigmas, uncert_pruning=True):\n",
    "            \"\"\" Performs weight pruning experiment\n",
    "            Args:\n",
    "                weightvalues_ibp: np array of weights with ibp mask applied\n",
    "                weightvalues: np array of weights\n",
    "                sigmavalues: np array of sigmas\n",
    "                weights: list of tf weight variable\n",
    "                sigmas: list of tf sigma variables\n",
    "                uncert_pruning: bool pruning by snr\n",
    "            \"\"\"\n",
    "            if uncert_pruning:\n",
    "                sorted_STN = np.sort(np.abs(weightvalues_ibp) / sigmavalues)\n",
    "            else:\n",
    "                sorted_STN = np.sort(np.abs(weightvalues))\n",
    "            cutoff = sorted_STN[int(remove_pct * len(sorted_STN))]\n",
    "            \n",
    "            # Weights, biases and head weights\n",
    "            for v, s in zip(weights, sigmas):\n",
    "                if uncert_pruning:\n",
    "                    snr = tf.abs(v) / tf.exp(0.5*s)\n",
    "                    mask = tf.greater_equal(snr, cutoff)\n",
    "                else:\n",
    "                    mask = tf.greater_equal(tf.abs(v), cutoff)\n",
    "                self.sess.run(tf.assign(v, tf.multiply(v, tf.cast(mask, v.dtype))))\n",
    "                self.sess.run(tf.assign(s, tf.multiply(s, tf.cast(mask, s.dtype))))  # also apply zero std to weight!!!\n",
    "                \n",
    "            \n",
    "            accs = []\n",
    "            for _ in range(10):\n",
    "                accs.append(self.sess.run(self.acc, {self.x: X_test,\n",
    "                                                     self.y: Y_test,\n",
    "                                                     self.task_idx: task_id,\n",
    "                                                     self.temp: self.lambda_1,\n",
    "                                                     self.training: False}))\n",
    "            print(\"%.2f, %s\" % (np.sum(sorted_STN < cutoff) / len(sorted_STN), np.mean(accs)))\n",
    "            return np.mean(accs)\n",
    "\n",
    "        # get weights\n",
    "        weights = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=tf.get_variable_scope().name)\n",
    "        \n",
    "        # Get weights from network\n",
    "        # TODO get head weights and biases\n",
    "        mus_w = []\n",
    "        mus_b = []\n",
    "        sigmas_w = []\n",
    "        sigmas_b = []\n",
    "        mus_h = [] # weights and biases\n",
    "        sigmas_h = [] # weights and biases\n",
    "        for v in weights:\n",
    "            if re.match(\"^([w])(_mu_)([0-9]+)(:0)$\", v.name):\n",
    "                mus_w.append(v)\n",
    "            elif re.match(\"^([w])(_sigma_)([0-9]+)(:0)$\", v.name):\n",
    "                sigmas_w.append(v)\n",
    "            elif re.match(\"^([b])(_mu_)([0-9]+)(:0)$\", v.name):\n",
    "                mus_b.append(v)\n",
    "            elif re.match(\"^([b])(_sigma_)([0-9]+)(:0)$\", v.name):\n",
    "                sigmas_b.append(v)\n",
    "            elif re.match(\"^([wb])(_mu_h_)([0-9]+)(:0)$\", v.name):\n",
    "                mus_h.append(v)\n",
    "            elif re.match(\"^([wb])(_sigma_h_)([0-9]+)(:0)$\", v.name):\n",
    "                sigmas_h.append(v)\n",
    "            else:\n",
    "                print(\"Un-matched: {}\".format(v.name))\n",
    "                \n",
    "        # Get mask\n",
    "        # Need to apply mask to weights and biases for pruning\n",
    "        # Do not apply to head weights though!\n",
    "        # Zs \\in [x_test.size, dout], just need one sample of Z!\n",
    "        Zs = self.sess.run(self.Z, {self.x: X_test,\n",
    "                                    self.y: Y_test,\n",
    "                                    self.task_idx: task_id,\n",
    "                                    self.temp: self.lambda_1,\n",
    "                                    self.training: False})[0] # z mask for each layer in a list, each Z \\in dout\n",
    "\n",
    "        # cache network weights of resetting the network\n",
    "        _mus_w = [self.sess.run(w) for w in mus_w]\n",
    "        _sigmas_w = [self.sess.run(w) for w in sigmas_w]\n",
    "        _mus_b = [self.sess.run(w) for w in mus_b]\n",
    "        _sigmas_b = [self.sess.run(w) for w in sigmas_b]\n",
    "        _mus_h = [self.sess.run(w) for w in mus_h]\n",
    "        _sigmas_h = [self.sess.run(w) for w in sigmas_h]\n",
    "\n",
    "        # flatten values for cut-off finding\n",
    "        # Tile Zs [dout] --> [din, dout]\n",
    "        dins = [x.shape[0] for x in _mus_w]\n",
    "        Z_tiled = []\n",
    "        t_Z_tiled = []\n",
    "        for i in range(len(dins)):\n",
    "            Z_tiled.append(np.tile(Zs[i][0, :], (dins[i], 1))) \n",
    "            t_Z_tiled.append(tf.tile(tf.squeeze(self.Z[i], axis=0), [dins[i], 1]))\n",
    "        \n",
    "        # multiply Zs with \n",
    "        xx = []\n",
    "        yy = []\n",
    "        for i in range(len(mus_w)):\n",
    "            xx.append(np.multiply(self.sess.run(mus_w[i]), Z_tiled[i]).flatten())\n",
    "            yy.append(np.multiply(self.sess.run(mus_b[i]), Zs[i][0,:]).flatten())\n",
    "        \n",
    "        # flatten head network weights\n",
    "        f_mus_h = []\n",
    "        f_sigmas_h = []\n",
    "        for i in range(len(f_mus_h)):\n",
    "            f_mus_h.append(f_mus_h[i].flatten())\n",
    "            f_sigmas_h.append(f_sigmas_h[i].flatten())\n",
    "        \n",
    "        weightvalues_ibp = np.hstack(np.array(xx + yy + f_mus_h))\n",
    "        weightvalues = np.hstack(np.array([self.sess.run(w).flatten() for w in mus_w + mus_b + f_mus_h]))\n",
    "        sigmavalues_tr = np.hstack(np.array([self.sess.run(tf.exp(0.5*s)).flatten() for s in sigmas_w + sigmas_b + f_sigmas_h]))\n",
    "    \n",
    "        xs = np.append(0.05 * np.array(range(20)), np.array([0.98, 0.99, 0.999]))\n",
    "        ya = []\n",
    "        for pct in xs:\n",
    "            ya.append(pruning(pct, weightvalues_ibp, weightvalues, sigmavalues_tr,\n",
    "                              mus_w + mus_b + f_mus_h, sigmas_w + sigmas_b + f_sigmas_h, \n",
    "                              uncert_pruning=False))\n",
    "\n",
    "        # reset etc.\n",
    "        reset_weights(mus_w, sigmas_w, _mus_w, _sigmas_w)\n",
    "        reset_weights(mus_b, sigmas_b, _mus_b, _sigmas_b)\n",
    "        yb = []\n",
    "        for pct in xs:\n",
    "            yb.append(pruning(pct, weightvalues_ibp, weightvalues, sigmavalues_tr,\n",
    "                              mus_w + mus_b + f_mus_h, sigmas_w + sigmas_b + f_sigmas_h,\n",
    "                              uncert_pruning=True))\n",
    "            \n",
    "        reset_weights(mus_w, sigmas_w, _mus_w, _sigmas_w)\n",
    "        reset_weights(mus_b, sigmas_b, _mus_b, _sigmas_b)\n",
    "        \n",
    "        return xs, ya, yb, weightvalues, sigmavalues_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.054196305\n",
      "Epoch: 0006 cost= 0.000863743\n",
      "Epoch: 0011 cost= 0.000250822\n",
      "Epoch: 0016 cost= 0.000103665\n",
      "Epoch: 0021 cost= 0.000056164\n",
      "Epoch: 0026 cost= 0.000033193\n",
      "Epoch: 0031 cost= 0.000021623\n",
      "Epoch: 0036 cost= 0.000014372\n",
      "Epoch: 0041 cost= 0.000009759\n",
      "Epoch: 0046 cost= 0.000006962\n",
      "Epoch: 0051 cost= 0.000005267\n",
      "Epoch: 0056 cost= 0.000003606\n",
      "Epoch: 0061 cost= 0.000002610\n",
      "Epoch: 0066 cost= 0.000001964\n",
      "Epoch: 0071 cost= 0.000001434\n",
      "Epoch: 0076 cost= 0.000001076\n",
      "Epoch: 0081 cost= 0.000000800\n",
      "Epoch: 0086 cost= 0.000000638\n",
      "Epoch: 0091 cost= 0.000000445\n",
      "Epoch: 0096 cost= 0.000000340\n",
      "Optimization Finished!\n",
      "z_discrete: (1, ?, 100)\n",
      "biases: <unknown>\n",
      "pre: <unknown>\n",
      "z_discrete: (1, ?, 100)\n",
      "biases: <unknown>\n",
      "pre: <unknown>\n",
      "z_discrete: (1, ?, 100)\n",
      "biases: <unknown>\n",
      "pre: <unknown>\n",
      "_Z: (1, ?, 100)\n",
      "Epoch: 0001 train cost= 19.067509160\n",
      "Epoch: 0006 train cost= 5.154825288\n",
      "Epoch: 0011 train cost= 3.800348641\n",
      "Epoch: 0016 train cost= 3.660439990\n",
      "Epoch: 0021 train cost= 3.549343988\n",
      "Epoch: 0026 train cost= 3.522964410\n",
      "Epoch: 0031 train cost= 3.423838536\n",
      "Epoch: 0036 train cost= 3.420067977\n",
      "Epoch: 0041 train cost= 3.373702979\n",
      "Epoch: 0046 train cost= 3.317197443\n",
      "Epoch: 0051 train cost= 3.256017220\n",
      "Epoch: 0056 train cost= 3.291766692\n",
      "Epoch: 0061 train cost= 3.283202997\n",
      "Epoch: 0066 train cost= 3.251356286\n",
      "Epoch: 0071 train cost= 3.197065274\n",
      "Epoch: 0076 train cost= 3.203330387\n",
      "Epoch: 0081 train cost= 3.211056647\n",
      "Epoch: 0086 train cost= 3.187440140\n",
      "Epoch: 0091 train cost= 3.171615528\n",
      "Epoch: 0096 train cost= 3.174036204\n",
      "Epoch: 0101 train cost= 3.149943224\n",
      "Epoch: 0106 train cost= 3.167393957\n",
      "Epoch: 0111 train cost= 3.169675998\n",
      "Epoch: 0116 train cost= 3.157255544\n",
      "Epoch: 0121 train cost= 3.160471512\n",
      "Epoch: 0126 train cost= 3.136914949\n",
      "Epoch: 0131 train cost= 3.123806498\n",
      "Epoch: 0136 train cost= 3.104472823\n",
      "Epoch: 0141 train cost= 3.130815256\n",
      "Epoch: 0146 train cost= 3.100806345\n",
      "Epoch: 0151 train cost= 3.154526802\n",
      "Epoch: 0156 train cost= 3.048786645\n",
      "Epoch: 0161 train cost= 3.119031070\n",
      "Epoch: 0166 train cost= 3.106174293\n",
      "Epoch: 0171 train cost= 3.096436110\n",
      "Epoch: 0176 train cost= 3.108014350\n",
      "Epoch: 0181 train cost= 3.075573290\n",
      "Epoch: 0186 train cost= 3.101514207\n",
      "Epoch: 0191 train cost= 3.091718850\n",
      "Epoch: 0196 train cost= 3.075598175\n",
      "Optimization Finished!\n",
      "Un-matched: w_0:0\n",
      "Un-matched: b_0:0\n",
      "Un-matched: w_h_0:0\n",
      "Un-matched: b_h_0:0\n",
      "Un-matched: beta_a_0:0\n",
      "Un-matched: beta_b_0:0\n",
      "0.00, 0.9972472\n",
      "0.00, 0.99719393\n",
      "0.00, 0.9974917\n",
      "0.00, 0.9969821\n",
      "0.00, 0.99695176\n",
      "0.00, 0.99711674\n",
      "0.00, 0.99706143\n",
      "0.00, 0.9972113\n",
      "0.00, 0.9970557\n",
      "0.00, 0.9974265\n",
      "0.00, 0.99703825\n",
      "0.00, 0.9970047\n",
      "0.00, 0.9971415\n",
      "0.00, 0.9970501\n",
      "0.00, 0.9969646\n",
      "0.00, 0.99720705\n",
      "0.00, 0.9970638\n",
      "0.85, 0.99725723\n",
      "0.90, 0.9967958\n",
      "0.95, 0.99664915\n",
      "0.98, 0.9972213\n",
      "0.99, 0.99728376\n",
      "1.00, 0.99542934\n"
     ]
    }
   ],
   "source": [
    "hidden_size = [100]\n",
    "batch_size = 128\n",
    "no_epochs = 200\n",
    "alpha0 = 1.0\n",
    "tau0=1.0 # initial temperature\n",
    "ANNEAL_RATE=0.000\n",
    "MIN_TEMP=0.1\n",
    "\n",
    "tf.set_random_seed(12)\n",
    "np.random.seed(1)\n",
    "\n",
    "ibp_acc = np.array([])\n",
    "\n",
    "coreset_size = 0\n",
    "val = False\n",
    "data_gen = SplitMnistGenerator(val, num_tasks=1)\n",
    "single_head=False\n",
    "in_dim, out_dim = data_gen.get_dims()\n",
    "x_testsets, y_testsets = [], []\n",
    "x_valsets, y_valsets = [], []\n",
    "for task_id in range(data_gen.max_iter):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    if val:\n",
    "        x_train, y_train, x_test, y_test, x_val, y_val = data_gen.next_task()\n",
    "        x_valsets.append(x_val)\n",
    "        y_valsets.append(y_val)\n",
    "    else:    \n",
    "        x_train, y_train, x_test, y_test = data_gen.next_task()\n",
    "    x_testsets.append(x_test)\n",
    "    y_testsets.append(y_test)\n",
    "\n",
    "    # Set the readout head to train\n",
    "    head = 0 if single_head else task_id\n",
    "    bsize = x_train.shape[0] if (batch_size is None) else batch_size\n",
    "    \n",
    "    # Train network with maximum likelihood to initialize first model\n",
    "    if task_id == 0:\n",
    "        ml_model = Vanilla_NN(in_dim, hidden_size, out_dim, x_train.shape[0])\n",
    "        ml_model.train(x_train, y_train, task_id, 100, bsize)\n",
    "        mf_weights = ml_model.get_weights()\n",
    "        mf_variances = None\n",
    "        mf_betas = None\n",
    "        ml_model.close_session()\n",
    "\n",
    "    # Train on non-coreset data\n",
    "    mf_model = MFVI_IBP_NN_prune(in_dim, hidden_size, out_dim, x_train.shape[0], prev_means=mf_weights, \n",
    "                           prev_log_variances=mf_variances, prev_betas=mf_betas,alpha0=alpha0,\n",
    "                           learning_rate=0.01, lambda_1=tau0, lambda_2=1.0, no_pred_samples=100)\n",
    "    mf_model.train(x_train, y_train, head, no_epochs, bsize,\n",
    "                   anneal_rate=ANNEAL_RATE, min_temp=MIN_TEMP)\n",
    "    \n",
    "    xs, ya, yb, _, _  = mf_model.prune_weights(x_test, y_test, head)\n",
    "    \n",
    "    mf_model.close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(xs, ya, label='$|\\mu|$')\n",
    "plt.plot(xs, yb, label='$ \\\\frac{|\\mu|}{\\sigma}$')\n",
    "plt.xlabel('cut-off')\n",
    "plt.ylabel('acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass CLF Weight Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistGenerator():\n",
    "    def __init__(self, max_iter=10):\n",
    "        with gzip.open('ddm/data/mnist.pkl.gz', 'rb') as f:\n",
    "            train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "\n",
    "        self.X_train = np.vstack((train_set[0], valid_set[0]))\n",
    "        self.Y_train = np.hstack((train_set[1], valid_set[1]))\n",
    "        self.X_test = test_set[0]\n",
    "        self.Y_test = test_set[1]\n",
    "        self.max_iter = max_iter\n",
    "        self.cur_iter = 0\n",
    "\n",
    "    def get_dims(self):\n",
    "        # Get data input and output dimensions\n",
    "        return self.X_train.shape[1], 10\n",
    "\n",
    "    def task(self):\n",
    "        # Retrieve train data\n",
    "        x_train = deepcopy(self.X_train)\n",
    "        y_train = np.eye(10)[self.Y_train]\n",
    "\n",
    "        # Retrieve test data\n",
    "        x_test = deepcopy(self.X_test)\n",
    "        y_test = np.eye(10)[self.Y_test]\n",
    "        \n",
    "        return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.408574541\n",
      "Epoch: 0006 cost= 0.074759072\n",
      "Epoch: 0011 cost= 0.035776014\n",
      "Epoch: 0016 cost= 0.018115912\n",
      "Epoch: 0021 cost= 0.009480936\n",
      "Epoch: 0026 cost= 0.004768397\n",
      "Epoch: 0031 cost= 0.004363418\n",
      "Epoch: 0036 cost= 0.005698155\n",
      "Epoch: 0041 cost= 0.000524980\n",
      "Epoch: 0046 cost= 0.000367317\n",
      "Epoch: 0051 cost= 0.005180777\n",
      "Epoch: 0056 cost= 0.000202681\n",
      "Epoch: 0061 cost= 0.000124391\n",
      "Epoch: 0066 cost= 0.000157842\n",
      "Epoch: 0071 cost= 0.000091161\n",
      "Epoch: 0076 cost= 0.010445531\n",
      "Epoch: 0081 cost= 0.000090337\n",
      "Epoch: 0086 cost= 0.000052465\n",
      "Epoch: 0091 cost= 0.000771823\n",
      "Epoch: 0096 cost= 0.000055726\n",
      "Optimization Finished!\n",
      "_Z: (1, ?, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0819 17:33:20.869965 140008901007168 deprecation.py:323] From /home/skessler/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un-matched: w_0:0\n",
      "Un-matched: b_0:0\n",
      "Un-matched: w_h_0:0\n",
      "Un-matched: b_h_0:0\n",
      "Un-matched: beta_a_0:0\n",
      "Un-matched: beta_b_0:0\n",
      "0.00, 0.92327654\n",
      "0.05, 0.9235799\n",
      "0.10, 0.92384684\n",
      "0.15, 0.92296094\n",
      "0.20, 0.92258966\n",
      "0.25, 0.9236393\n",
      "0.30, 0.92348444\n",
      "0.35, 0.9230534\n",
      "0.40, 0.9232804\n",
      "0.45, 0.92349374\n",
      "0.50, 0.92324525\n",
      "0.55, 0.92340314\n",
      "0.60, 0.92254096\n",
      "0.65, 0.9204912\n",
      "0.70, 0.9074329\n",
      "0.75, 0.8741002\n",
      "0.80, 0.8230032\n",
      "0.85, 0.7541254\n",
      "0.90, 0.6573881\n",
      "0.95, 0.50270617\n",
      "0.98, 0.3179967\n",
      "0.99, 0.23368928\n",
      "1.00, 0.1267716\n",
      "0.00, 0.9236741\n",
      "0.00, 0.9232396\n",
      "0.00, 0.92255974\n",
      "0.00, 0.92225707\n",
      "0.00, 0.9233879\n",
      "0.00, 0.92320204\n",
      "0.30, 0.9230297\n",
      "0.35, 0.92319334\n",
      "0.40, 0.92318326\n",
      "0.45, 0.92354095\n",
      "0.50, 0.9230132\n",
      "0.55, 0.92322814\n",
      "0.60, 0.92365617\n",
      "0.65, 0.922624\n",
      "0.70, 0.9230455\n",
      "0.75, 0.92294866\n",
      "0.80, 0.92293864\n",
      "0.85, 0.9170517\n",
      "0.90, 0.89981115\n",
      "0.95, 0.83589095\n",
      "0.98, 0.7055582\n",
      "0.99, 0.5721121\n",
      "1.00, 0.260612\n"
     ]
    }
   ],
   "source": [
    "hidden_size = [100]\n",
    "batch_size = 128\n",
    "no_epochs = 500\n",
    "ANNEAL_RATE=0.000\n",
    "MIN_TEMP=0.1\n",
    "\n",
    "tf.set_random_seed(12)\n",
    "np.random.seed(1)\n",
    "\n",
    "ibp_acc = np.array([])\n",
    "\n",
    "coreset_size = 0\n",
    "data_gen = MnistGenerator()\n",
    "single_head=False\n",
    "in_dim, out_dim = data_gen.get_dims()\n",
    "x_testsets, y_testsets = [], []\n",
    "task_id=0\n",
    "    \n",
    "tf.reset_default_graph()  \n",
    "x_train, y_train, x_test, y_test = data_gen.task()\n",
    "x_testsets.append(x_test)\n",
    "y_testsets.append(y_test)\n",
    "\n",
    "# Set the readout head to train\n",
    "head = 0 if single_head else task_id\n",
    "bsize = x_train.shape[0] if (batch_size is None) else batch_size\n",
    "\n",
    "# Train network with maximum likelihood to initialize first model\n",
    "if task_id == 0:\n",
    "    ml_model = Vanilla_NN(in_dim, hidden_size, out_dim, x_train.shape[0])\n",
    "    ml_model.train(x_train, y_train, task_id, 100, bsize)\n",
    "    mf_weights = ml_model.get_weights()\n",
    "    mf_variances = None\n",
    "    mf_betas = None\n",
    "    ml_model.close_session()\n",
    "\n",
    "# Train on non-coreset data\n",
    "mf_model = MFVI_IBP_NN_prune(in_dim, hidden_size, out_dim, x_train.shape[0], prev_means=mf_weights, \n",
    "                       prev_log_variances=mf_variances, prev_betas=mf_betas,alpha0=5.0, beta0=1.0,\n",
    "                       learning_rate=0.0001, lambda_1=1.0, lambda_2=1.0, no_pred_samples=100,\n",
    "                       name='ibp_wp_mnist')\n",
    "\n",
    "mf_model.restore(os.path.join(\"logs\", \"graph_{}_task{}\".format('ibp_wp_mnist', 0)))\n",
    "# mf_model.train(x_train, y_train, head, no_epochs, bsize,\n",
    "#                anneal_rate=ANNEAL_RATE, min_temp=MIN_TEMP)\n",
    "\n",
    "xs, ya, yb, _, _  = mf_model.prune_weights(x_test, y_test, head)\n",
    "\n",
    "mf_model.close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(xs, ya, label='$|\\mu|$')\n",
    "plt.plot(xs, yb, label='snr')\n",
    "plt.xlabel('cut-off')\n",
    "plt.ylabel('acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
